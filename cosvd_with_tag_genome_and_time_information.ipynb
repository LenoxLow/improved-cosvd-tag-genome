{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import (absolute_import, division, print_function,\n",
    "                        unicode_literals)\n",
    "\n",
    "#cimport numpy as np # noqa\n",
    "import numpy as np\n",
    "\n",
    "from surprise import Reader, AlgoBase, PredictionImpossible\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.utils import get_rng\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, mean_absolute_error, precision_score, recall_score\n",
    "from math import sqrt\n",
    "\n",
    "#%reload_ext Cython\n",
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## co-SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "cimport numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "from surprise import AlgoBase, PredictionImpossible\n",
    "from surprise.utils import get_rng\n",
    "from functools import reduce\n",
    "from cython.parallel import prange\n",
    "\n",
    "class co_SVD(AlgoBase):\n",
    "    def __init__ (\n",
    "        self\n",
    "        , n_factors = 40\n",
    "        , n_epochs = 1\n",
    "        , biased = True\n",
    "        , init_mean = 0\n",
    "        , init_std_dev=.1\n",
    "\n",
    "        , lr_all=.005\n",
    "        , reg_all=.02\n",
    "        , lr_bu=None\n",
    "        , lr_bi=None\n",
    "        , lr_bt=None\n",
    "        , lr_pu=None\n",
    "        , lr_qi=None\n",
    "        , lr_rt=None\n",
    "\n",
    "        , reg_p=.001\n",
    "        , reg_r=.035\n",
    "        , reg_f=1.5\n",
    "\n",
    "        , random_state=None\n",
    "        , verbose=False\n",
    "        , p_ut=None\n",
    "        , f_it=None\n",
    "        , tags=None\n",
    "        , ratings=None\n",
    "        ):\n",
    "\n",
    "        self.n_factors = n_factors\n",
    "        self.n_epochs = n_epochs\n",
    "        self.biased = biased\n",
    "        self.init_mean = init_mean\n",
    "        self.init_std_dev = init_std_dev\n",
    "        self.lr_bu = lr_bu if lr_bu is not None else lr_all\n",
    "        self.lr_bi = lr_bi if lr_bi is not None else lr_all\n",
    "        self.lr_bt = lr_bt if lr_bt is not None else lr_all\n",
    "\n",
    "        self.lr_pu = lr_pu if lr_pu is not None else lr_all\n",
    "        self.lr_qi = lr_qi if lr_qi is not None else lr_all\n",
    "        self.lr_rt = lr_rt if lr_rt is not None else lr_all\n",
    "\n",
    "        self.reg_p = reg_p\n",
    "        self.reg_f = reg_f\n",
    "        self.reg_r = reg_r\n",
    "\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.p_ut = p_ut\n",
    "        self.f_it = f_it\n",
    "        self.tags = tags\n",
    "        self.ratings = ratings\n",
    "        AlgoBase.__init__(self)\n",
    "        \n",
    "   \n",
    "  \n",
    "    def fit(self,trainset):\n",
    "        AlgoBase.fit(self, trainset)       \n",
    "        self.sgd(trainset)\n",
    "        return self\n",
    "\n",
    "    def sgd(self, trainset):\n",
    "        cdef np.ndarray[np.double_t] bu\n",
    "        cdef np.ndarray[np.double_t] bi\n",
    "        cdef np.ndarray[np.double_t] bt\n",
    "\n",
    "        cdef np.ndarray[np.double_t, ndim=2] pu\n",
    "        cdef np.ndarray[np.double_t, ndim=2] qi\n",
    "        cdef np.ndarray[np.double_t, ndim=2] rt\n",
    "\n",
    "        cdef int u, i, t, f, raw_u, raw_i, raw_t\n",
    "        cdef double r, p_put, p_fit, err_r, err_p, err_f, dot_r, dot_p, dot_f, puf, qif, rtf, global_mean_p, global_mean_f\n",
    "        cdef double global_mean_r = self.trainset.global_mean\n",
    "\n",
    "        cdef double lr_bu = self.lr_bu\n",
    "        cdef double lr_bi = self.lr_bi\n",
    "        cdef double lr_bt = self.lr_bt\n",
    "\n",
    "        cdef double lr_pu = self.lr_pu\n",
    "        cdef double lr_qi = self.lr_qi\n",
    "        cdef double lr_rt = self.lr_rt\n",
    "\n",
    "        cdef double reg_p = self.reg_p\n",
    "        cdef double reg_f = self.reg_f\n",
    "        cdef double reg_r = self.reg_r\n",
    "\n",
    "        p_ut = self.p_ut\n",
    "        f_it = self.f_it\n",
    "        tags = self.tags\n",
    "        ratings = self.ratings\n",
    "        \n",
    "        cdef int n_factors = self.n_factors\n",
    "        raw_user = np.zeros(trainset.n_users, int)\n",
    "        for i in trainset.all_users():\n",
    "            raw_user[i] = trainset.to_raw_uid(i)\n",
    "\n",
    "        raw_item = np.zeros(trainset.n_items, int)\n",
    "        for i in trainset.all_items():\n",
    "            raw_item[i] = trainset.to_raw_iid(i)\n",
    "        \n",
    "        final_raw = ratings[ratings.userId.isin(raw_user) & ratings.movieId.isin(raw_item)]\n",
    "        raw_data = final_raw\n",
    "\n",
    "        uni_tid = raw_data.tid.unique()\n",
    "        uni_tid = uni_tid[~np.isnan(uni_tid)]\n",
    "        u_t = pd.DataFrame({'tid': uni_tid,\n",
    "                            'tid_inner':range(len(uni_tid))})\n",
    "        \n",
    "        raw_data = pd.merge(raw_data, u_t, how ='left', on=['tid'])\n",
    "        \n",
    "        final_p = p_ut[p_ut.userId.isin(raw_user) & p_ut.tid.isin(raw_data.tid)]\n",
    "        final_f = f_it[f_it.movieId.isin(raw_item) & f_it.tid.isin(raw_data.tid)]\n",
    "        \n",
    "        final_p = pd.merge(final_p, u_t, how='left', on=['tid'])\n",
    "        final_f = pd.merge(final_f, u_t, how='left', on=['tid'])\n",
    "\n",
    "        p_ut = final_p.drop(['tid'], axis=1)\n",
    "        f_it = final_f.drop(['tid'], axis=1)\n",
    "\n",
    "        rng = get_rng(self.random_state)\n",
    "        \n",
    "        bu = np.zeros(trainset.n_users, np.double)\n",
    "        bi = np.zeros(trainset.n_items, np.double)\n",
    "\n",
    "        bt = np.zeros(len(p_ut.tid_inner.unique()), np.double)\n",
    "        \n",
    "        pu = rng.normal(self.init_mean, self.init_std_dev,\n",
    "                        (trainset.n_users, self.n_factors))\n",
    "        qi = rng.normal(self.init_mean, self.init_std_dev,\n",
    "                        (trainset.n_items, self.n_factors))\n",
    "        rt = rng.normal(self.init_mean, self.init_std_dev,\n",
    "                        (len(p_ut.tid_inner.unique()), self.n_factors))\n",
    "        \n",
    "        global_mean_p = np.mean(p_ut.val)\n",
    "        global_mean_f = np.mean(f_it.val)\n",
    "        \n",
    "        \n",
    "        for current_epoch in range(self.n_epochs):\n",
    "            if self.verbose:\n",
    "                print(\"Processing epoch {}\".format(current_epoch), end='\\r')\n",
    "\n",
    "            rv_sum = np.zeros((trainset.n_users, self.n_factors))\n",
    "            pz_sum = np.zeros((trainset.n_users, self.n_factors))\n",
    "            ru_sum = np.zeros((trainset.n_items, self.n_factors))\n",
    "            fz_sum = np.zeros((trainset.n_items, self.n_factors))\n",
    "            pu_sum = np.zeros((len(p_ut.tid_inner.unique()), self.n_factors))\n",
    "            fv_sum = np.zeros((len(p_ut.tid_inner.unique()), self.n_factors))\n",
    "            \n",
    "            for rn in range(len(raw_data)):\n",
    "                \n",
    "                raw_u = raw_data.loc[rn, 'userId']\n",
    "                raw_i = raw_data.loc[rn, 'movieId']\n",
    "                \n",
    "                u = trainset.to_inner_uid(raw_u)\n",
    "                i = trainset.to_inner_iid(raw_i)\n",
    "                \n",
    "                r = raw_data.loc[rn, 'rating']\n",
    "                if pd.isna(raw_data.loc[rn, 'tid_inner']) | np.isnan(raw_data.loc[rn, 'tid_inner']):\n",
    "                    t = -1\n",
    "                else:\n",
    "                    t = raw_data.loc[rn, 'tid_inner']\n",
    "                \n",
    "                t = int(t)\n",
    "                \n",
    "                if t != -1:\n",
    "                    p_put = list(p_ut.val[(p_ut.userId == raw_u) & (p_ut.tid_inner == t)])[0]\n",
    "                    p_fit = list(f_it.val[(f_it.movieId == raw_i) & (f_it.tid_inner == t)])[0]\n",
    "\n",
    "                if math.isnan(r):\n",
    "                    r = 0\n",
    "\n",
    "                dot_r = 0.0\n",
    "                dot_p = 0.0\n",
    "                dot_f = 0.0\n",
    "                if r != 0:\n",
    "                    for f in prange(n_factors, nogil=True):\n",
    "                        dot_r += qi[i,f] * pu[u,f] \n",
    "\n",
    "                if t != -1:\n",
    "                    for f in range(n_factors):\n",
    "                        dot_p += rt[t,f] * pu[u,f]\n",
    "                        dot_f += rt[t,f] * qi[i,f]\n",
    "                \n",
    "                if not(math.isnan(r)):\n",
    "                    err_r = r - (global_mean_r + bu[u] + bi[i] + dot_r)\n",
    "                else:\n",
    "                    err_r = 0.0\n",
    "\n",
    "                if t != -1:\n",
    "                    err_p = p_put - (global_mean_p + bu[u] + bt[t] + dot_p)\n",
    "                    err_f = p_fit - (global_mean_f + bi[i] + bt[t] + dot_f)\n",
    "                else:\n",
    "                    err_p = 0.0\n",
    "                    err_f = 0.0\n",
    "\n",
    "                if self.biased:\n",
    "                    bu[u] -= lr_bu * (-1 * err_r - reg_p * err_p + reg_r * bu[u])\n",
    "                    bi[i] -= lr_bi * (-1 * err_r - reg_f * err_f + reg_r * bi[i])\n",
    "                    if t != -1:\n",
    "                        bt[t] -= lr_bt * (-1 * reg_p * err_p - reg_f * err_f + reg_r * bt[t])\n",
    "                \n",
    "                for f in range(self.n_factors):\n",
    "                    rv_sum[u,f] += err_r * qi[i,f]\n",
    "                    ru_sum[i,f] += err_r * pu[u,f]\n",
    "                    if t != -1:\n",
    "                        pz_sum[u,f] += err_p * rt[t,f]\n",
    "                        fz_sum[i,f] += err_f * rt[t,f]\n",
    "                        pu_sum[t,f] += err_p * pu[u,f]\n",
    "                        fv_sum[t,f] += err_f * qi[i,f]\n",
    "            \n",
    "            for f in range(self.n_factors):\n",
    "                for u in trainset.all_users():              \n",
    "                    puf = pu[u,f]\n",
    "                    pu[u,f] -= lr_pu * (-1 * rv_sum[u,f] - reg_p * pz_sum[u,f] + reg_r * puf)\n",
    "                    \n",
    "                for i in trainset.all_items():\n",
    "                    qif = qi[i,f]\n",
    "                    qi[i,f] -= lr_pu * (-1 * ru_sum[i,f] - reg_f * fz_sum[i,f] + reg_r * qif)\n",
    "                       \n",
    "                for t in range(len(p_ut.tid_inner.unique())):\n",
    "                    rtf = rt[t, f]\n",
    "                    rt[t,f] -= lr_pu * (-1 * reg_p * pu_sum[t,f] - reg_f * fv_sum[t,f] + reg_r * rtf)\n",
    "                    \n",
    "        self.bu = bu\n",
    "        self.bi = bi\n",
    "        self.pu = pu\n",
    "        self.qi = qi\n",
    "\n",
    "    def estimate(self, u, i):\n",
    "        known_user = self.trainset.knows_user(u)\n",
    "        known_item = self.trainset.knows_item(i)\n",
    "\n",
    "        if self.biased:\n",
    "            est = self.trainset.global_mean\n",
    "\n",
    "            if known_user:\n",
    "                est += self.bu[u]\n",
    "\n",
    "            if known_item:\n",
    "                est += self.bi[i]\n",
    "                \n",
    "            if known_user and known_item:\n",
    "                est += np.dot(self.qi[i], self.pu[u])\n",
    "        else:\n",
    "            if known_user and known_item:\n",
    "                est = np.dot(self.qi[i], self.pu[u])\n",
    "            else:\n",
    "                raise PredictionImpossible('User and item are unknown')\n",
    "        return est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate User-Tag Matrix & Item-Tag Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTagsOrigin(rate, tags):\n",
    "    temp_df = rate\n",
    "    temp_df = temp_df.iloc[:,0:3]\n",
    "    \n",
    "    gb_tags = tags.groupby(['tag'], as_index=False)['userId'].count()\n",
    "    uni_tags = gb_tags.tag[gb_tags.userId >= 5].reset_index(drop=True)\n",
    "    tags = tags[tags.tag.isin(uni_tags)].reset_index(drop=True)\n",
    "    if len(uni_tags) ==0 :\n",
    "        print(\"Not tags available\")\n",
    "    uni_tags = {'tag':uni_tags, 'tid':range(len(uni_tags))}\n",
    "    u_tag = pd.DataFrame(uni_tags)\n",
    "    tags = pd.merge(tags, u_tag, how='left', on=['tag'])\n",
    "\n",
    "    w = tags.groupby(['tid', 'movieId'], as_index=False)['userId'].count()\n",
    "    w.columns = ['tid', 'movieId', 'cn']\n",
    "    temp = w.groupby('movieId', as_index=False)['cn'].sum()\n",
    "    temp = temp.set_index('movieId')\n",
    "    iteration = range(len(w))\n",
    "    w['val'] = np.array(pd.Series(iteration).map(lambda x: w.cn[x] / temp.loc[w.movieId[1], 'cn']))\n",
    "    \n",
    "    f = tags.groupby(['userId', 'tid'], as_index=False).agg({'movieId': 'count'})\n",
    "    f.columns = ['userId', 'tid', 'cn']\n",
    "    temp = f.groupby('userId', as_index=False)['cn'].sum()\n",
    "    temp = temp.set_index('userId')\n",
    "    iteration = range(len(f))\n",
    "    f['val'] = np.array(pd.Series(iteration).map(lambda x: f.cn[x] / temp.loc[f.userId[x], 'cn']))\n",
    "    \n",
    "    nl_alpha = -0.006\n",
    "    \n",
    "    nl_ut = tags.groupby(['userId', 'tid'], as_index=False).agg({'timestamp': 'max'})\n",
    "    nl_ut = nl_ut.sort_values(by=['userId', 'timestamp'], ascending=[True,False]).reset_index(drop=True)\n",
    "    g = nl_ut.groupby(['userId'])\n",
    "    nl_ut['times'] = g['timestamp'].rank(method='first', ascending=False)\n",
    "    nl_ut['val'] = nl_alpha * nl_ut['times']\n",
    "    nl_ut['val'] = nl_ut['val'].map(lambda x: math.exp(x)).tolist()\n",
    "    \n",
    "    nl_it = tags.groupby(['movieId', 'tid'], as_index=False).agg({'timestamp': 'max'})\n",
    "    nl_it = nl_it.sort_values(by=['movieId', 'timestamp'], ascending=[True,False]).reset_index(drop=True)\n",
    "    g = nl_it.groupby(['movieId'])\n",
    "    nl_it['times'] = g['timestamp'].rank(method='first', ascending=False)\n",
    "    nl_it['val'] = nl_alpha * nl_it['times']\n",
    "    nl_it['val'] = nl_it['val'].map(lambda x: math.exp(x)).tolist()\n",
    "    \n",
    "    ru = temp_df.groupby(['userId'], as_index=False).agg({'rating': 'mean'})\n",
    "    ru = ru.rename(index=str, columns={\"rating\": \"ru\"})\n",
    "    p_ut = pd.DataFrame(f[['userId','tid']], columns=['userId','tid'])\n",
    "    how='outer'\n",
    "    overall = pd.merge(temp_df, tags, how=how, on=['userId', 'movieId'])\n",
    "    overall = overall.drop(columns=['tag','timestamp'])\n",
    "    overall.rating.fillna(0, inplace=True)\n",
    "    temp_rt = overall[ (-pd.isna(overall.userId)) & (-pd.isna(overall.tid))]\n",
    "    rt = overall.groupby(['userId', 'tid'], as_index=False).agg({'rating': 'mean'})\n",
    "    rt = rt.rename(index=str, columns={\"rating\": \"rt\"})\n",
    "    overall = pd.merge(overall, w, how=how, on=['movieId', 'tid'])\n",
    "    overall = overall.drop(columns=['cn'])\n",
    "    overall = overall.rename(index=str, columns={\"val\": \"w_it\"})\n",
    "    overall.w_it.fillna(0, inplace=True)\n",
    "    overall = pd.merge(overall, ru, how=how, on=['userId'])\n",
    "    overall.ru.fillna(0, inplace=True)\n",
    "    overall['r_bias'] = overall.rating - overall.ru\n",
    "    overall['b_it'] = overall.r_bias * overall.w_it\n",
    "    b_it = overall[-pd.isna(overall.tid)].groupby(['userId', 'tid'], as_index=False).agg({'w_it': 'sum', 'b_it':'sum'})\n",
    "    b_it['val'] = b_it.b_it / b_it.w_it\n",
    "    \n",
    "    ru = ru.set_index('userId')\n",
    "    rt = rt.set_index(['userId', 'tid'])\n",
    "    f = f.set_index(['userId', 'tid'])\n",
    "    b_it = b_it.set_index(['userId', 'tid'])\n",
    "    nl_ut = nl_ut.set_index(['userId', 'tid'])\n",
    "\n",
    "    p_ut['val'] = list(map(lambda x,y: ru.loc[x, 'ru'] + b_it.loc[(x, y), 'val'] \n",
    "              + 1.7 * f.loc[(x,y),'val'] * (rt.loc[(x,y), 'rt'] - ru.loc[x, 'ru']) \n",
    "              + 0.05 * nl_ut.loc[(x,y), 'val'] , p_ut.userId, p_ut.tid))\n",
    "    \n",
    "    f_it = pd.DataFrame(w[['movieId','tid']], columns=['movieId','tid'])\n",
    "    w = w.set_index(['movieId', 'tid'])\n",
    "    nl_it = nl_it.set_index(['movieId', 'tid'])\n",
    "    f_it['val'] = list(map(lambda x,y: w.loc[(x,y), 'val'] + 0.05 * nl_it.loc[(x,y), 'val'], f_it.movieId, f_it.tid))\n",
    "    \n",
    "    ratings = overall.iloc[:,0:4]\n",
    "    return p_ut, f_it, tags, ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Item-Tag Matrix with Tag Genome & User-Tag Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTagsWithGenomeScore(rate, tags, genome_tag, genome_score):\n",
    "    temp_df = rate\n",
    "    temp_df = temp_df.iloc[:,0:3]\n",
    "    \n",
    "    gb_tags = tags.groupby(['tag'], as_index=False)['userId'].count()\n",
    "    tags = tags[tags.tag.isin(list(gb_tags.tag[gb_tags.userId >= 5]))].reset_index(drop=True)\n",
    "    tags.tag = tags.tag.apply(lambda x: x.lower())\n",
    "\n",
    "    tags = pd.merge(tags, genome_tag, how='left', on=['tag'])\n",
    "    tags = tags[~np.isnan(tags.tagId)]\n",
    "    tags = tags[tags.movieId.isin(genome_score.movieId) & tags.tagId.isin(genome_score.tagId)]\n",
    "    \n",
    "    uni_tags = tags.groupby(['tag'], as_index=False)['userId'].count().tag\n",
    "    tags = tags[tags.tag.isin(uni_tags)].reset_index(drop=True)\n",
    "    uni_tags = {'tag':uni_tags, 'tid':range(len(uni_tags))}\n",
    "    u_tag = pd.DataFrame(uni_tags)\n",
    "    tags = pd.merge(tags, u_tag, how='left', on=['tag'])\n",
    "    \n",
    "    f_it = genome_score[genome_score.movieId.isin(tags.movieId) & genome_score.tagId.isin(tags.tagId)]\n",
    "    temp_tag = tags.iloc[:, -2:]\n",
    "    temp_tag = temp_tag.drop_duplicates()\n",
    "    f_it = pd.merge(f_it, temp_tag, how='left', on=['tagId'])\n",
    "    f_it = f_it.rename(index=str, columns={\"relevance\": \"val\"})\n",
    "    \n",
    "    f_it = f_it.drop(['tagId'], axis=1)\n",
    "    tags = tags.drop(['tagId'], axis=1)\n",
    "    \n",
    "    w = tags.groupby(['tid', 'movieId'], as_index=False)['userId'].count()\n",
    "    w.columns = ['tid', 'movieId', 'cn']\n",
    "    temp = w.groupby('movieId', as_index=False)['cn'].sum()\n",
    "    temp = temp.set_index('movieId')\n",
    "    iteration = range(len(w))\n",
    "    w['val'] = pd.Series(iteration).map(lambda x: w.cn[x] / temp.loc[w.movieId[1], 'cn']).tolist()\n",
    "    \n",
    "    f = tags.groupby(['userId', 'tid'], as_index=False).agg({'movieId': 'count'})\n",
    "    f.columns = ['userId', 'tid', 'cn']\n",
    "    temp = f.groupby('userId', as_index=False)['cn'].sum()\n",
    "    temp = temp.set_index('userId')\n",
    "    iteration = range(len(f))\n",
    "    f['val'] = pd.Series(iteration).map(lambda x: f.cn[x] / temp.loc[f.userId[x], 'cn']).tolist()\n",
    "    \n",
    "    nl_alpha = -0.006\n",
    "    \n",
    "    nl_ut = tags.groupby(['userId', 'tid'], as_index=False).agg({'timestamp': 'max'})\n",
    "    nl_ut = nl_ut.sort_values(by=['userId', 'timestamp'], ascending=[True,False]).reset_index(drop=True)\n",
    "    g = nl_ut.groupby(['userId'])\n",
    "    nl_ut['times'] = g['timestamp'].rank(method='first', ascending=False)\n",
    "    nl_ut['val'] = nl_alpha * nl_ut['times']\n",
    "    nl_ut['val'] = nl_ut['val'].map(lambda x: math.exp(x)).tolist()\n",
    "    \n",
    "    ru = temp_df.groupby(['userId'], as_index=False).agg({'rating': 'mean'})\n",
    "    ru = ru.rename(index=str, columns={\"rating\": \"ru\"})\n",
    "    p_ut = pd.DataFrame(f[['userId','tid']], columns=['userId','tid'])\n",
    "    how='outer'\n",
    "    overall = pd.merge(temp_df, tags, how=how, on=['userId', 'movieId'])\n",
    "    overall = overall.drop(columns=['tag','timestamp'])\n",
    "    overall.rating.fillna(0, inplace=True)\n",
    "    temp_rt = overall[ (-pd.isna(overall.userId)) & (-pd.isna(overall.tid))]\n",
    "    rt = overall.groupby(['userId', 'tid'], as_index=False).agg({'rating': 'mean'})\n",
    "    rt = rt.rename(index=str, columns={\"rating\": \"rt\"})\n",
    "    overall = pd.merge(overall, w, how=how, on=['movieId', 'tid'])\n",
    "    overall = overall.drop(columns=['cn'])\n",
    "    overall = overall.rename(index=str, columns={\"val\": \"w_it\"})\n",
    "    overall.w_it.fillna(0, inplace=True)\n",
    "    overall = pd.merge(overall, ru, how=how, on=['userId'])\n",
    "    overall.ru.fillna(0, inplace=True)\n",
    "    overall['r_bias'] = overall.rating - overall.ru\n",
    "    overall['b_it'] = overall.r_bias * overall.w_it\n",
    "    b_it = overall[-pd.isna(overall.tid)].groupby(['userId', 'tid'], as_index=False).agg({'w_it': 'sum', 'b_it':'sum'})\n",
    "    b_it['val'] = b_it.b_it / b_it.w_it\n",
    "    \n",
    "    ru = ru.set_index('userId')\n",
    "    rt = rt.set_index(['userId', 'tid'])\n",
    "    f = f.set_index(['userId', 'tid'])\n",
    "    b_it = b_it.set_index(['userId', 'tid'])\n",
    "    nl_ut = nl_ut.set_index(['userId', 'tid'])\n",
    "\n",
    "    p_ut['val'] = list(map(lambda x,y: ru.loc[x, 'ru'] + b_it.loc[(x, y), 'val'] \n",
    "              + 1.7 * f.loc[(x,y),'val'] * (rt.loc[(x,y), 'rt'] - ru.loc[x, 'ru']) \n",
    "              + 0.05 * nl_ut.loc[(x,y), 'val'] , p_ut.userId, p_ut.tid))\n",
    "    \n",
    "    ratings = overall.iloc[:,0:4]\n",
    "    return p_ut, f_it, tags, ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Item-Tag Matrix with Tag genome and time information & User-Tag Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTagsWeightageWithGenomeScore(rate, tags, genome_tag, genome_score):\n",
    "    temp_df = rate\n",
    "    temp_df = temp_df.iloc[:,0:3]\n",
    "      \n",
    "    gb_tags = tags.groupby(['tag'], as_index=False)['userId'].count()\n",
    "    tags = tags[tags.tag.isin(list(gb_tags.tag[gb_tags.userId >= 5]))].reset_index(drop=True)\n",
    "    tags.tag = tags.tag.apply(lambda x: x.lower())\n",
    "\n",
    "    tags = pd.merge(tags, genome_tag, how='left', on=['tag'])\n",
    "    tags = tags[~np.isnan(tags.tagId)]\n",
    "    tags = tags[tags.movieId.isin(genome_score.movieId) & tags.tagId.isin(genome_score.tagId)]\n",
    "    \n",
    "    uni_tags = tags.groupby(['tag'], as_index=False)['userId'].count().tag\n",
    "    tags = tags[tags.tag.isin(uni_tags)].reset_index(drop=True)\n",
    "    uni_tags = {'tag':uni_tags, 'tid':range(len(uni_tags))}\n",
    "    u_tag = pd.DataFrame(uni_tags)\n",
    "    tags = pd.merge(tags, u_tag, how='left', on=['tag'])\n",
    "    \n",
    "    temp_tag = tags.iloc[:, -2:]\n",
    "    temp_tag = temp_tag.drop_duplicates()\n",
    "    tags = tags.drop(['tagId'], axis=1)\n",
    "    #f_it = genome_score[genome_score.movieId.isin(tags.movieId) & genome_score.tagId.isin(tags.tagId)]\n",
    "    \n",
    "    w = tags.groupby(['tid', 'movieId'], as_index=False)['userId'].count()\n",
    "    w.columns = ['tid', 'movieId', 'cn']\n",
    "    temp = w.groupby('movieId', as_index=False)['cn'].sum()\n",
    "    temp = temp.set_index('movieId')\n",
    "    iteration = range(len(w))\n",
    "    w['val'] = pd.Series(iteration).map(lambda x: w.cn[x] / temp.loc[w.movieId[1], 'cn']).tolist()\n",
    "    \n",
    "    f = tags.groupby(['userId', 'tid'], as_index=False).agg({'movieId': 'count'})\n",
    "    f.columns = ['userId', 'tid', 'cn']\n",
    "    temp = f.groupby('userId', as_index=False)['cn'].sum()\n",
    "    temp = temp.set_index('userId')\n",
    "    iteration = range(len(f))\n",
    "    f['val'] = pd.Series(iteration).map(lambda x: f.cn[x] / temp.loc[f.userId[x], 'cn']).tolist()\n",
    "    \n",
    "    nl_alpha = -0.006\n",
    "    \n",
    "    nl_ut = tags.groupby(['userId', 'tid'], as_index=False).agg({'timestamp': 'max'})\n",
    "    nl_ut = nl_ut.sort_values(by=['userId', 'timestamp'], ascending=[True,False]).reset_index(drop=True)\n",
    "    g = nl_ut.groupby(['userId'])\n",
    "    nl_ut['times'] = g['timestamp'].rank(method='first', ascending=False)\n",
    "    nl_ut['val'] = nl_alpha * nl_ut['times']\n",
    "    nl_ut['val'] = nl_ut['val'].map(lambda x: math.exp(x)).tolist()\n",
    "    \n",
    "    nl_it = tags.groupby(['movieId', 'tid'], as_index=False).agg({'timestamp': 'max'})\n",
    "    nl_it = nl_it.sort_values(by=['movieId', 'timestamp'], ascending=[True,False]).reset_index(drop=True)\n",
    "    g = nl_it.groupby(['movieId'])\n",
    "    nl_it['times'] = g['timestamp'].rank(method='first', ascending=False)\n",
    "    nl_it['val'] = nl_alpha * nl_it['times']\n",
    "    nl_it['val'] = nl_it['val'].map(lambda x: math.exp(x)).tolist()\n",
    "    \n",
    "    ru = temp_df.groupby(['userId'], as_index=False).agg({'rating': 'mean'})\n",
    "    ru = ru.rename(index=str, columns={\"rating\": \"ru\"})\n",
    "    p_ut = pd.DataFrame(f[['userId','tid']], columns=['userId','tid'])\n",
    "    how='outer'\n",
    "    overall = pd.merge(temp_df, tags, how=how, on=['userId', 'movieId'])\n",
    "    overall = overall.drop(columns=['tag','timestamp'])\n",
    "    overall.rating.fillna(0, inplace=True)\n",
    "    temp_rt = overall[ (-pd.isna(overall.userId)) & (-pd.isna(overall.tid))]\n",
    "    rt = overall.groupby(['userId', 'tid'], as_index=False).agg({'rating': 'mean'})\n",
    "    rt = rt.rename(index=str, columns={\"rating\": \"rt\"})\n",
    "    overall = pd.merge(overall, w, how=how, on=['movieId', 'tid'])\n",
    "    overall = overall.drop(columns=['cn'])\n",
    "    overall = overall.rename(index=str, columns={\"val\": \"w_it\"})\n",
    "    overall.w_it.fillna(0, inplace=True)\n",
    "    overall = pd.merge(overall, ru, how=how, on=['userId'])\n",
    "    overall.ru.fillna(0, inplace=True)\n",
    "    overall['r_bias'] = overall.rating - overall.ru\n",
    "    overall['b_it'] = overall.r_bias * overall.w_it\n",
    "    b_it = overall[-pd.isna(overall.tid)].groupby(['userId', 'tid'], as_index=False).agg({'w_it': 'sum', 'b_it':'sum'})\n",
    "    b_it['val'] = b_it.b_it / b_it.w_it\n",
    "    \n",
    "    ru = ru.set_index('userId')\n",
    "    rt = rt.set_index(['userId', 'tid'])\n",
    "    f = f.set_index(['userId', 'tid'])\n",
    "    b_it = b_it.set_index(['userId', 'tid'])\n",
    "    nl_ut = nl_ut.set_index(['userId', 'tid'])\n",
    "\n",
    "    p_ut['val'] = list(map(lambda x,y: ru.loc[x, 'ru'] + b_it.loc[(x, y), 'val'] \n",
    "              + 1.7 * f.loc[(x,y),'val'] * (rt.loc[(x,y), 'rt'] - ru.loc[x, 'ru']) \n",
    "              + 0.05 * nl_ut.loc[(x,y), 'val'] , p_ut.userId, p_ut.tid))\n",
    "    \n",
    "    genome_score = genome_score[genome_score.movieId.isin(tags.movieId) & genome_score.tagId.isin(temp_tag.tagId)]\n",
    "    genome_score = pd.merge(genome_score, temp_tag, how='left', on=['tagId'])\n",
    "    genome_score = genome_score.rename(index=str, columns={\"relevance\": \"val\"})\n",
    "    \n",
    "    f_it = pd.DataFrame(w[['movieId','tid']], columns=['movieId','tid'])\n",
    "    genome_score = genome_score.set_index(['movieId', 'tid'])\n",
    "    nl_it = nl_it.set_index(['movieId', 'tid'])\n",
    "    f_it['val'] = list(map(lambda x,y: genome_score.loc[(x,y), 'val'] + 0.05 * nl_it.loc[(x,y), 'val'], f_it.movieId, f_it.tid))\n",
    "    \n",
    "    ratings = overall.iloc[:,0:4]\n",
    "    return p_ut, f_it, tags, ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Item-Tag Matrix with tag genome, tag frequency and time information & User-Tag Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTagsOriginWithGenomeWeightage(rate, tags, genome_tag, genome_score):\n",
    "    temp_df = rate\n",
    "    temp_df = temp_df.iloc[:,0:3]\n",
    "    \n",
    "    gb_tags = tags.groupby(['tag'], as_index=False)['userId'].count()\n",
    "    tags = tags[tags.tag.isin(list(gb_tags.tag[gb_tags.userId >= 5]))].reset_index(drop=True)\n",
    "    tags.tag = tags.tag.apply(lambda x: x.lower())\n",
    "\n",
    "    tags = pd.merge(tags, genome_tag, how='left', on=['tag'])\n",
    "    tags = tags[~np.isnan(tags.tagId)]\n",
    "    tags = tags[tags.movieId.isin(genome_score.movieId) & tags.tagId.isin(genome_score.tagId)]\n",
    "    \n",
    "    uni_tags = tags.groupby(['tag'], as_index=False)['userId'].count().tag\n",
    "    tags = tags[tags.tag.isin(uni_tags)].reset_index(drop=True)\n",
    "    uni_tags = {'tag':uni_tags, 'tid':range(len(uni_tags))}\n",
    "    u_tag = pd.DataFrame(uni_tags)\n",
    "    tags = pd.merge(tags, u_tag, how='left', on=['tag'])\n",
    "    \n",
    "    temp_tag = tags.iloc[:, -2:]\n",
    "    temp_tag = temp_tag.drop_duplicates()\n",
    "    tags = tags.drop(['tagId'], axis=1)\n",
    "    \n",
    "    w = tags.groupby(['tid', 'movieId'], as_index=False)['userId'].count()\n",
    "    w.columns = ['tid', 'movieId', 'cn']\n",
    "    temp = w.groupby('movieId', as_index=False)['cn'].sum()\n",
    "    temp = temp.set_index('movieId')\n",
    "    iteration = range(len(w))\n",
    "    w['val'] = pd.Series(iteration).map(lambda x: w.cn[x] / temp.loc[w.movieId[1], 'cn']).tolist()\n",
    "    \n",
    "    f = tags.groupby(['userId', 'tid'], as_index=False).agg({'movieId': 'count'})\n",
    "    f.columns = ['userId', 'tid', 'cn']\n",
    "    temp = f.groupby('userId', as_index=False)['cn'].sum()\n",
    "    temp = temp.set_index('userId')\n",
    "    iteration = range(len(f))\n",
    "    f['val'] = pd.Series(iteration).map(lambda x: f.cn[x] / temp.loc[f.userId[x], 'cn']).tolist()\n",
    "    \n",
    "    nl_alpha = -0.006\n",
    "    \n",
    "    nl_ut = tags.groupby(['userId', 'tid'], as_index=False).agg({'timestamp': 'max'})\n",
    "    nl_ut = nl_ut.sort_values(by=['userId', 'timestamp'], ascending=[True,False]).reset_index(drop=True)\n",
    "    g = nl_ut.groupby(['userId'])\n",
    "    nl_ut['times'] = g['timestamp'].rank(method='first', ascending=False)\n",
    "    nl_ut['val'] = nl_alpha * nl_ut['times']\n",
    "    nl_ut['val'] = nl_ut['val'].map(lambda x: math.exp(x)).tolist()\n",
    "    \n",
    "    nl_it = tags.groupby(['movieId', 'tid'], as_index=False).agg({'timestamp': 'max'})\n",
    "    nl_it = nl_it.sort_values(by=['movieId', 'timestamp'], ascending=[True,False]).reset_index(drop=True)\n",
    "    g = nl_it.groupby(['movieId'])\n",
    "    nl_it['times'] = g['timestamp'].rank(method='first', ascending=False)\n",
    "    nl_it['val'] = nl_alpha * nl_it['times']\n",
    "    nl_it['val'] = nl_it['val'].map(lambda x: math.exp(x)).tolist()\n",
    "    \n",
    "    ru = temp_df.groupby(['userId'], as_index=False).agg({'rating': 'mean'})\n",
    "    ru = ru.rename(index=str, columns={\"rating\": \"ru\"})\n",
    "    p_ut = pd.DataFrame(f[['userId','tid']], columns=['userId','tid'])\n",
    "    how='outer'\n",
    "    overall = pd.merge(temp_df, tags, how=how, on=['userId', 'movieId'])\n",
    "    overall = overall.drop(columns=['tag','timestamp'])\n",
    "    overall.rating.fillna(0, inplace=True)\n",
    "    temp_rt = overall[ (-pd.isna(overall.userId)) & (-pd.isna(overall.tid))]\n",
    "    rt = overall.groupby(['userId', 'tid'], as_index=False).agg({'rating': 'mean'})\n",
    "    rt = rt.rename(index=str, columns={\"rating\": \"rt\"})\n",
    "    overall = pd.merge(overall, w, how=how, on=['movieId', 'tid'])\n",
    "    overall = overall.drop(columns=['cn'])\n",
    "    overall = overall.rename(index=str, columns={\"val\": \"w_it\"})\n",
    "    overall.w_it.fillna(0, inplace=True)\n",
    "    overall = pd.merge(overall, ru, how=how, on=['userId'])\n",
    "    overall.ru.fillna(0, inplace=True)\n",
    "    overall['r_bias'] = overall.rating - overall.ru\n",
    "    overall['b_it'] = overall.r_bias * overall.w_it\n",
    "    b_it = overall[-pd.isna(overall.tid)].groupby(['userId', 'tid'], as_index=False).agg({'w_it': 'sum', 'b_it':'sum'})\n",
    "    b_it['val'] = b_it.b_it / b_it.w_it\n",
    "    \n",
    "    ru = ru.set_index('userId')\n",
    "    rt = rt.set_index(['userId', 'tid'])\n",
    "    f = f.set_index(['userId', 'tid'])\n",
    "    b_it = b_it.set_index(['userId', 'tid'])\n",
    "    nl_ut = nl_ut.set_index(['userId', 'tid'])\n",
    "\n",
    "    p_ut['val'] = list(map(lambda x,y: ru.loc[x, 'ru'] + b_it.loc[(x, y), 'val'] \n",
    "              + 1.7 * f.loc[(x,y),'val'] * (rt.loc[(x,y), 'rt'] - ru.loc[x, 'ru']) \n",
    "              + 0.05 * nl_ut.loc[(x,y), 'val'] , p_ut.userId, p_ut.tid))\n",
    "    \n",
    "    genome_score = genome_score[genome_score.movieId.isin(tags.movieId) & genome_score.tagId.isin(temp_tag.tagId)]\n",
    "    genome_score = pd.merge(genome_score, temp_tag, how='left', on=['tagId'])\n",
    "    genome_score = genome_score.rename(index=str, columns={\"relevance\": \"val\"})\n",
    "    \n",
    "    f_it = pd.DataFrame(w[['movieId','tid']], columns=['movieId','tid'])\n",
    "    w = w.set_index(['movieId', 'tid'])\n",
    "    genome_score = genome_score.set_index(['movieId', 'tid'])\n",
    "    nl_it = nl_it.set_index(['movieId', 'tid'])\n",
    "    f_it['val'] = list(map(lambda x,y: genome_score.loc[(x,y), 'val'] + 0.05 * nl_it.loc[(x,y), 'val'] if (x,y) in genome_score.index else w.loc[(x,y), 'val'] + 0.05 * nl_it.loc[(x,y), 'val'], f_it.movieId, f_it.tid))\n",
    "    \n",
    "    ratings = overall.iloc[:,0:4]\n",
    "    return p_ut, f_it, tags, ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = 'mlsmall'          # MovieLens dataset 2018\n",
    "#data_source = 'ml-latest-small' # MovieLens dataset 2016\n",
    "reader = Reader()\n",
    "path = os.path.join('Dataset',data_source)\n",
    "rate = pd.read_csv(path+'/ratings.csv', encoding='utf-8')\n",
    "raw_tags = pd.read_csv(path+'/tags.csv', encoding='utf-8')\n",
    "\n",
    "data = Dataset.load_from_df(rate[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "## The Tag Genome dataset obtain from MovieLens latest 27M dataset\n",
    "path = os.path.join('Dataset', 'ml-latest')\n",
    "genome_tag = pd.read_csv(path+'/genome-tags.csv', encoding='utf-8')\n",
    "genome_score = pd.read_csv(path+'/genome-scores.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the value of settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr  = 0.0073 # Learning Rate of the co-SVD\n",
    "epoch = 20 # The number of iteration for model training\n",
    "n_eval = 10 # The number of iteration for model evaluation\n",
    "rdm_state = 1 # Random Seed for train test data split\n",
    "\n",
    "factors = 40 # the number of latent features, may change to 20, 30 or 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate co-SVD with Fixed Seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5869150348669047\n",
      "MAE: 0.4430839735008973\n",
      "Precision: 0.907002457002457\n",
      "Recall: 0.7964830897027887\n"
     ]
    }
   ],
   "source": [
    "## Generate the User-Tag (p_ut) & Item-Tag (f_it) Matrices\n",
    "p_ut, f_it, tags, ratings = generateTagsOrigin(rate, raw_tags)\n",
    "\n",
    "## Dataset Train Test Split with 7:3 ratio\n",
    "trainset, testset = train_test_split(data, test_size=.3, random_state = rdm_state)\n",
    "\n",
    "## Initial the co-SVD Model\n",
    "algo = co_SVD(verbose=False, n_epochs=epoch, lr_all=lr, n_factors=factors\n",
    "              , p_ut=p_ut, f_it=f_it, tags=tags, ratings=ratings\n",
    "             , random_state=123\n",
    "             )\n",
    "\n",
    "## Model Training\n",
    "algo.fit(trainset)\n",
    "\n",
    "## Model Testing\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "## Model Evaluation\n",
    "mae = accuracy.mae(predictions, verbose=False)\n",
    "rmse = accuracy.rmse(predictions, verbose=False)\n",
    "\n",
    "test_res = pd.DataFrame(predictions)\n",
    "\n",
    "threshold = 3.5\n",
    "test_res['actual_cat'] = list(map(lambda x: 1 if x >= threshold else 0, test_res['r_ui']))\n",
    "test_res['pred_cat'] = list(map(lambda x: 1 if x >= threshold else 0, test_res['est']))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(test_res.actual_cat, test_res.pred_cat).ravel()\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "if data_source == \"ml_small\":\n",
    "    print(\"MovieLens Dataset 2018\")\n",
    "elif data_source == \"ml-latest-small\":\n",
    "    print(\"MovieLens Dataset 2016\")\n",
    "    \n",
    "print( \"RMSE: \"+ str(rmse) + \"\\n\" + \"MAE: \" + str(mae) + \"\\n\" + \"Precision: \" + str(precision) + \"\\n\" + \"Recall: \" + str(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate different approach on constructing Item-Tag Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Method - Result\n",
      "precision    0.907373\n",
      "recall       0.796130\n",
      "rmse         0.583199\n",
      "mae          0.441311\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Generate Item-Tag Matrix & User-Tag Matrix\n",
    "p_ut, f_it, tags, ratings = generateTagsOrigin(rate, raw_tags)\n",
    "\n",
    "res = pd.DataFrame(columns = ['n_eval', 'precision' , 'recall', 'rmse', 'mae'])\n",
    "\n",
    "for j in range(n_eval):\n",
    "    trainset, testset = train_test_split(data, test_size=.3, random_state=j)\n",
    "    algo = co_SVD(verbose=False, n_epochs=epoch, lr_all=lr, n_factors=factors\n",
    "                  , p_ut=p_ut, f_it=f_it, tags=tags, ratings=ratings, random_state=123\n",
    "                 )\n",
    "\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    mae = accuracy.mae(predictions, verbose=False)\n",
    "    rmse = accuracy.rmse(predictions, verbose=False)\n",
    "\n",
    "    test_res = pd.DataFrame(predictions)\n",
    "\n",
    "    threshold = 3.5\n",
    "    test_res['actual_cat'] = list(map(lambda x: 1 if x >= threshold else 0, test_res['r_ui']))\n",
    "    test_res['pred_cat'] = list(map(lambda x: 1 if x >= threshold else 0, test_res['est']))\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(test_res.actual_cat, test_res.pred_cat).ravel()\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    res = res.append(pd.Series([j, precision, recall, rmse, mae], index=res.columns), ignore_index = True)\n",
    "    \n",
    "if data_source == \"ml_small\":\n",
    "    print(\"MovieLens Dataset 2018\")\n",
    "elif data_source == \"ml-latest-small\":\n",
    "    print(\"MovieLens Dataset 2016\")\n",
    "\n",
    "print(\"Original Method - Result\")\n",
    "print(res.drop(columns=['n_eval']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method I - Result\n",
      "precision    0.908524\n",
      "recall       0.806932\n",
      "rmse         0.569686\n",
      "mae          0.429751\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Generate Item-Tag Matrix with Tag Genome & User-Tag Matrix\n",
    "p_ut, f_it, tags, ratings = generateTagsWithGenomeScore(rate, raw_tags, genome_tag, genome_score)\n",
    "\n",
    "res = pd.DataFrame(columns = ['n_eval', 'precision' , 'recall', 'rmse', 'mae'])\n",
    "\n",
    "for j in range(n_eval):\n",
    "    trainset, testset = train_test_split(data, test_size=.3, random_state=j)\n",
    "    algo = co_SVD(verbose=False, n_epochs=epoch, lr_all=lr, n_factors=factors\n",
    "                  , p_ut=p_ut, f_it=f_it, tags=tags, ratings=ratings, random_state=123\n",
    "                 )\n",
    "\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    mae = accuracy.mae(predictions, verbose=False)\n",
    "    rmse = accuracy.rmse(predictions, verbose=False)\n",
    "\n",
    "    test_res = pd.DataFrame(predictions)\n",
    "\n",
    "    threshold = 3.5\n",
    "    test_res['actual_cat'] = list(map(lambda x: 1 if x >= threshold else 0, test_res['r_ui']))\n",
    "    test_res['pred_cat'] = list(map(lambda x: 1 if x >= threshold else 0, test_res['est']))\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(test_res.actual_cat, test_res.pred_cat).ravel()\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    res = res.append(pd.Series([j, precision, recall, rmse, mae], index=res.columns), ignore_index = True)\n",
    "    \n",
    "if data_source == \"ml_small\":\n",
    "    print(\"MovieLens Dataset 2018\")\n",
    "elif data_source == \"ml-latest-small\":\n",
    "    print(\"MovieLens Dataset 2016\")\n",
    "\n",
    "print(\"Method I - Result\")\n",
    "print(res.drop(columns=['n_eval']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method II - Result\n",
      "precision    0.908345\n",
      "recall       0.806921\n",
      "rmse         0.569663\n",
      "mae          0.429775\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Generate Item-Tag Matrix with Tag genome and time information & User-Tag Matrix\n",
    "p_ut, f_it, tags, ratings = generateTagsWeightageWithGenomeScore(rate, raw_tags, genome_tag, genome_score)\n",
    "\n",
    "res = pd.DataFrame(columns = ['n_eval', 'precision' , 'recall', 'rmse', 'mae'])\n",
    "\n",
    "for j in range(n_eval):\n",
    "    start = time.time()\n",
    "    trainset, testset = train_test_split(data, test_size=.3, random_state=j)\n",
    "    algo = co_SVD(verbose=False, n_epochs=epoch, lr_all=lr, n_factors=factors\n",
    "                  , p_ut=p_ut, f_it=f_it, tags=tags, ratings=ratings, random_state=123\n",
    "                 )\n",
    "\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    mae = accuracy.mae(predictions, verbose=False)\n",
    "    rmse = accuracy.rmse(predictions, verbose=False)\n",
    "\n",
    "    test_res = pd.DataFrame(predictions)\n",
    "\n",
    "    threshold = 3.5\n",
    "    test_res['actual_cat'] = list(map(lambda x: 1 if x >= threshold else 0, test_res['r_ui']))\n",
    "    test_res['pred_cat'] = list(map(lambda x: 1 if x >= threshold else 0, test_res['est']))\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(test_res.actual_cat, test_res.pred_cat).ravel()\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    res = res.append(pd.Series([j, precision, recall, rmse, mae], index=res.columns), ignore_index = True)\n",
    "    duration = time.time() - start\n",
    "    \n",
    "if data_source == \"ml_small\":\n",
    "    print(\"MovieLens Dataset 2018\")\n",
    "elif data_source == \"ml-latest-small\":\n",
    "    print(\"MovieLens Dataset 2016\")\n",
    "\n",
    "print(\"Method II - Result\")\n",
    "print(res.drop(columns=['n_eval']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method III - Result\n",
      "precision    0.908345\n",
      "recall       0.806921\n",
      "rmse         0.569663\n",
      "mae          0.429775\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Generate Item-Tag Matrix with tag genome, tag frequency and time information & User-Tag Matrix\n",
    "p_ut, f_it, tags, ratings = generateTagsOriginWithGenomeWeightage(rate, raw_tags, genome_tag, genome_score)\n",
    "\n",
    "res = pd.DataFrame(columns = ['n_eval', 'precision' , 'recall', 'rmse', 'mae'])\n",
    "\n",
    "for j in range(n_eval):\n",
    "    start = time.time()\n",
    "    trainset, testset = train_test_split(data, test_size=.3, random_state=j)\n",
    "    algo = co_SVD(verbose=False, n_epochs=epoch, lr_all=lr, n_factors=factors\n",
    "                  , p_ut=p_ut, f_it=f_it, tags=tags, ratings=ratings, random_state=123\n",
    "                 )\n",
    "\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    mae = accuracy.mae(predictions, verbose=False)\n",
    "    rmse = accuracy.rmse(predictions, verbose=False)\n",
    "\n",
    "    test_res = pd.DataFrame(predictions)\n",
    "\n",
    "    threshold = 3.5\n",
    "    test_res['actual_cat'] = list(map(lambda x: 1 if x >= threshold else 0, test_res['r_ui']))\n",
    "    test_res['pred_cat'] = list(map(lambda x: 1 if x >= threshold else 0, test_res['est']))\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(test_res.actual_cat, test_res.pred_cat).ravel()\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    res = res.append(pd.Series([j, precision, recall, rmse, mae], index=res.columns), ignore_index = True)\n",
    "    duration = time.time() - start\n",
    "    \n",
    "if data_source == \"ml_small\":\n",
    "    print(\"MovieLens Dataset 2018\")\n",
    "elif data_source == \"ml-latest-small\":\n",
    "    print(\"MovieLens Dataset 2016\")\n",
    "\n",
    "print(\"Method III - Result\")\n",
    "print(res.drop(columns=['n_eval']).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
